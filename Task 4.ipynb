{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6729fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "#importing necessory libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ddaf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.csv' , encoding = 'ISO-8859-1') #reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01f40dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() #gives first  entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90ecc6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail() #gives last 5  entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddbf0fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>0</td>\n",
       "      <td>Let me know how it changes in the next 6hrs. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>0</td>\n",
       "      <td>TELL HER I SAID EAT SHIT.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0</td>\n",
       "      <td>Too late. I said i have the website. I didn't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>0</td>\n",
       "      <td>Give one miss from that number please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>0</td>\n",
       "      <td>Hi. Hope you had a good day. Have a better night.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>1</td>\n",
       "      <td>You have 1 new message. Please call 08715205273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>0</td>\n",
       "      <td>Just sent you an email ÛÒ to an address with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2686</th>\n",
       "      <td>0</td>\n",
       "      <td>There r many model..sony ericson also der.. &amp;l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>0</td>\n",
       "      <td>It's cool, let me know before it kicks off aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>0</td>\n",
       "      <td>Y lei?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Target                                            Message\n",
       "3043       0  Let me know how it changes in the next 6hrs. I...\n",
       "1295       0                          TELL HER I SAID EAT SHIT.\n",
       "245        0  Too late. I said i have the website. I didn't ...\n",
       "1752       0              Give one miss from that number please\n",
       "5398       0  Hi. Hope you had a good day. Have a better night.\n",
       "5110       1    You have 1 new message. Please call 08715205273\n",
       "1472       0  Just sent you an email ÛÒ to an address with ...\n",
       "2686       0  There r many model..sony ericson also der.. &l...\n",
       "1583       0  It's cool, let me know before it kicks off aro...\n",
       "1681       0                                             Y lei?"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a08ade80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cbd6f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27860"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec7bbd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()  # give inforamtion about dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2baa959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>bt not his girlfrnd... G o o d n i g h t . . .@\"</td>\n",
       "      <td>MK17 92H. 450Ppw 16\"</td>\n",
       "      <td>GNT:-)\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          v1                      v2  \\\n",
       "count   5572                    5572   \n",
       "unique     2                    5169   \n",
       "top      ham  Sorry, I'll call later   \n",
       "freq    4825                      30   \n",
       "\n",
       "                                               Unnamed: 2  \\\n",
       "count                                                  50   \n",
       "unique                                                 43   \n",
       "top      bt not his girlfrnd... G o o d n i g h t . . .@\"   \n",
       "freq                                                    3   \n",
       "\n",
       "                   Unnamed: 3 Unnamed: 4  \n",
       "count                      12          6  \n",
       "unique                     10          5  \n",
       "top      MK17 92H. 450Ppw 16\"    GNT:-)\"  \n",
       "freq                        2          2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()   #gives Description about dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c8d25fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Target', 'Message'], dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f427063d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f746c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a45fcdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns={'v1':'Target','v2':'Message'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ec959ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target     0\n",
       "Message    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92cb6552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "925ac498",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep='first',inplace=True) #removing duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd4764f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86e68997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10338"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f03a4fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "5567    1\n",
       "5568    0\n",
       "5569    0\n",
       "5570    0\n",
       "5571    0\n",
       "Name: Target, Length: 5169, dtype: int32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labe encoding \n",
    "encoder=LabelEncoder()\n",
    "df['Target']=encoder.fit_transform(df['Target'])\n",
    "df['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24842c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target                                            Message\n",
       "0       0  Go until jurong point, crazy.. Available only ...\n",
       "1       0                      Ok lar... Joking wif u oni...\n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       0  U dun say so early hor... U c already then say...\n",
       "4       0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bcc70e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pie(df['Target'].value_counts(), labels = ['ham', 'spam'], autopct = \"%0.2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e38adf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['Message']\n",
    "y=df['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d28b9a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Go until jurong point, crazy.. Available only ...\n",
      "1                           Ok lar... Joking wif u oni...\n",
      "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3       U dun say so early hor... U c already then say...\n",
      "4       Nah I don't think he goes to usf, he lives aro...\n",
      "                              ...                        \n",
      "5567    This is the 2nd time we have tried 2 contact u...\n",
      "5568                Will Ì_ b going to esplanade fr home?\n",
      "5569    Pity, * was in mood for that. So...any other s...\n",
      "5570    The guy did some bitching but I acted like i'd...\n",
      "5571                           Rofl. Its true to its name\n",
      "Name: Message, Length: 5169, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f29f7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "5567    1\n",
       "5568    0\n",
       "5569    0\n",
       "5570    0\n",
       "5571    0\n",
       "Name: Target, Length: 5169, dtype: int32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a691ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=3)  #splitting data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3eee40d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77b1fa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cv = cv.fit_transform(x_train)\n",
    "x_test_cv = cv.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93e7d29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1879)\t1\n",
      "  (0, 1170)\t1\n",
      "  (0, 6840)\t1\n",
      "  (0, 6610)\t1\n",
      "  (0, 2779)\t1\n",
      "  (1, 1939)\t1\n",
      "  (1, 4467)\t1\n",
      "  (1, 453)\t1\n",
      "  (1, 7176)\t1\n",
      "  (1, 7594)\t1\n",
      "  (1, 1577)\t1\n",
      "  (1, 203)\t1\n",
      "  (1, 4768)\t1\n",
      "  (1, 7175)\t1\n",
      "  (1, 7390)\t1\n",
      "  (1, 7590)\t1\n",
      "  (1, 4309)\t1\n",
      "  (1, 5157)\t1\n",
      "  (1, 3732)\t1\n",
      "  (1, 3015)\t1\n",
      "  (1, 2333)\t1\n",
      "  (1, 5210)\t1\n",
      "  (1, 4577)\t1\n",
      "  (1, 4731)\t1\n",
      "  (1, 5615)\t1\n",
      "  :\t:\n",
      "  (4134, 3290)\t2\n",
      "  (4134, 4817)\t1\n",
      "  (4134, 1546)\t1\n",
      "  (4134, 4195)\t1\n",
      "  (4134, 891)\t1\n",
      "  (4134, 1092)\t1\n",
      "  (4134, 1261)\t1\n",
      "  (4134, 7302)\t1\n",
      "  (4134, 6595)\t1\n",
      "  (4134, 1624)\t1\n",
      "  (4134, 1977)\t1\n",
      "  (4134, 7438)\t1\n",
      "  (4134, 6189)\t1\n",
      "  (4134, 6815)\t1\n",
      "  (4134, 2357)\t1\n",
      "  (4134, 4093)\t1\n",
      "  (4134, 6583)\t1\n",
      "  (4134, 5934)\t1\n",
      "  (4134, 1661)\t1\n",
      "  (4134, 5153)\t1\n",
      "  (4134, 6292)\t1\n",
      "  (4134, 3707)\t1\n",
      "  (4134, 6172)\t1\n",
      "  (4134, 3624)\t1\n",
      "  (4134, 4785)\t1\n"
     ]
    }
   ],
   "source": [
    "print(x_train_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a2eeb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression() # training model logistic training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69b7a1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(x_train_cv,y_train)\n",
    "prediction_train=lr.predict(x_train_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85553a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy : 99.75816203143893\n"
     ]
    }
   ],
   "source": [
    "print( \"Acuuracy :\",accuracy_score(y_train, prediction_train)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15e81f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = lr.predict(x_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06b9dd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 97.58220502901354\n"
     ]
    }
   ],
   "source": [
    "print( \" Accuracy:\" ,accuracy_score(y_test, prediction_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89ad3e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def changement(email):\n",
    "    # Your implementation for processing the email\n",
    "    # For example, converting to lowercase\n",
    "    return email.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "399cb65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "someemailaddress@example.com\n"
     ]
    }
   ],
   "source": [
    "user_mail = \"SomeEmailAddress@Example.com\"\n",
    "processed = changement(user_mail)\n",
    "print(processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41d8dfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the text of the email :\n",
      "\n",
      "sakshitripathi@gmail.com\n"
     ]
    }
   ],
   "source": [
    "user_mail = input(\"Enter the text of the email :\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f27b22e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'someemailaddress@example.com'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed=changement(user_mail)\n",
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9670763f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Feature Extraction :\n",
      "\n",
      "   (0, 1)\t1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming you have a function named 'changement' for processing the email\n",
    "def changement(email):\n",
    "    # Your implementation for processing the email\n",
    "    # For example, converting to lowercase\n",
    "    return email.lower()\n",
    "\n",
    "# Example email\n",
    "user_mail = \"SomeEmailAddress@Example.com\"\n",
    "\n",
    "# Process the email\n",
    "processed = changement(user_mail)\n",
    "\n",
    "# Creating a TfidfVectorizer for feature extraction\n",
    "feature_extraction = TfidfVectorizer()\n",
    "\n",
    "# Examples of training data\n",
    "training_data = [\"example email text 1\", \"example email text 2\", \"example email text 3\"]\n",
    "\n",
    "# Fiting the vectorizer on the training data\n",
    "feature_extraction.fit(training_data)\n",
    "\n",
    "# Transforming the processed email using the fitted vectorizer\n",
    "input_data_features = feature_extraction.transform([processed])\n",
    "\n",
    "# Print the features\n",
    "print(\"After Feature Extraction :\\n\\n\", input_data_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2521712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Output:\n",
      "\n",
      " [0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming you have a function named 'changement' for processing the email\n",
    "def changement(email):\n",
    "    # Your implementation for processing the email\n",
    "    # For example, converting to lowercase\n",
    "    return email.lower()\n",
    "\n",
    "# Example email\n",
    "user_mail = \"SomeEmailAddress@Example.com\"\n",
    "\n",
    "# Process the email\n",
    "processed = changement(user_mail)\n",
    "\n",
    "# Example training data and labels\n",
    "training_data = [\"example email text 1\", \"example email text 2\", \"example email text 3\"]\n",
    "labels = [0, 1, 0]  # Replace with your actual labels (0 or 1)\n",
    "\n",
    "# Create a TfidfVectorizer for feature extraction\n",
    "feature_extraction = TfidfVectorizer()\n",
    "X_train = feature_extraction.fit_transform(training_data)\n",
    "\n",
    "# Create and train the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, labels)\n",
    "\n",
    "# Transform the processed email using the fitted vectorizer\n",
    "input_data_features = feature_extraction.transform([processed])\n",
    "\n",
    "# Make predictions\n",
    "predicted_output = model.predict(input_data_features)\n",
    "\n",
    "# Print the predicted output\n",
    "print(\"Predicted Output:\\n\\n\", predicted_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cfe5bf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Spam mail\n"
     ]
    }
   ],
   "source": [
    "if (predicted_output[0]==1):\n",
    "    print('Spam mail')\n",
    "else:\n",
    "    print('Non-Spam mail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1c1e8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.9.2-cp311-cp311-win_amd64.whl (151 kB)\n",
      "                                              0.0/151.4 kB ? eta -:--:--\n",
      "     ---------------------                   81.9/151.4 kB 2.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 151.4/151.4 kB 3.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\sakshi tripathi\\anaconda3\\lib\\site-packages (from wordcloud) (1.24.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\sakshi tripathi\\anaconda3\\lib\\site-packages (from wordcloud) (9.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sakshi tripathi\\anaconda3\\lib\\site-packages (from wordcloud) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sakshi tripathi\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sakshi tripathi\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sakshi tripathi\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sakshi tripathi\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sakshi tripathi\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (23.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sakshi tripathi\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sakshi tripathi\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sakshi tripathi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "225e5933",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Sakshi\n",
      "[nltk_data]     Tripathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Sakshi\n",
      "[nltk_data]     Tripathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Sakshi\n",
      "[nltk_data]     Tripathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Sakshi\n",
      "[nltk_data]     Tripathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Sakshi Tripathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "from os import walk\n",
    "from string import punctuation\n",
    "from random import shuffle\n",
    "from collections import Counter\n",
    "import multiprocessing\n",
    "import email\n",
    "\n",
    "\n",
    "import sklearn as sk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6b1456cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for (root,dirs,files) in os.walk('enron_dataset', topdown=True):\n",
    "    print (root)\n",
    "    print (dirs)\n",
    "    print (files)\n",
    "    print ('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "90c12b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathwalk = walk(r\"spam.csv\")\n",
    "\n",
    "allHamData, allSpamData = [], []\n",
    "for root, dr, file in pathwalk:\n",
    "    if 'ham' in str(file):\n",
    "        for obj in file:\n",
    "            with open(root + '/' + obj, encoding='latin1') as ip:\n",
    "                allHamData.append(\" \".join(ip.readlines()))\n",
    "                \n",
    "    elif 'spam' in str(file):\n",
    "        for obj in file:\n",
    "            with open(root + '/' + obj, encoding='latin1') as ip:\n",
    "                allSpamData.append(\" \".join(ip.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1d22efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamPlusSpamData = allHamData + allSpamData\n",
    "labels = [\"ham\"]*len(allHamData) + [\"spam\"]*len(allSpamData)\n",
    "\n",
    "raw_df = pd.DataFrame({\"email\": hamPlusSpamData, \n",
    "                       \"label\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2379d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 0 entries\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   email   0 non-null      float64\n",
      " 1   label   0 non-null      float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 132.0 bytes\n"
     ]
    }
   ],
   "source": [
    "raw_df.info() #checking or exploring data for null or duplicate values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129f2d95",
   "metadata": {},
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1e0dcc51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Message</th>\n",
       "      <th>body_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target                                            Message  \\\n",
       "0       0  Go until jurong point, crazy.. Available only ...   \n",
       "1       0                      Ok lar... Joking wif u oni...   \n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3       0  U dun say so early hor... U c already then say...   \n",
       "4       0  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                     body_text_clean  \n",
       "0  Go until jurong point crazy Available only in ...  \n",
       "1                            Ok lar Joking wif u oni  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...  \n",
       "3        U dun say so early hor U c already then say  \n",
       "4  Nah I dont think he goes to usf he lives aroun...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "# Function to remove punctuations.\n",
    "def remove_punc(text):\n",
    "    nonP_text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return nonP_text\n",
    "\n",
    "df[\"body_text_clean\"] = df[\"Message\"].apply(lambda x: remove_punc(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3359521c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Message</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[Go, until, jurong, point, crazy, Available, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[U, dun, say, so, early, hor, U, c, already, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[Nah, I, dont, think, he, goes, to, usf, he, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target                                            Message  \\\n",
       "0       0  Go until jurong point, crazy.. Available only ...   \n",
       "1       0                      Ok lar... Joking wif u oni...   \n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3       0  U dun say so early hor... U c already then say...   \n",
       "4       0  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Go until jurong point crazy Available only in ...   \n",
       "1                            Ok lar Joking wif u oni   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3        U dun say so early hor U c already then say   \n",
       "4  Nah I dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                 body_text_tokenized  \n",
       "0  [Go, until, jurong, point, crazy, Available, o...  \n",
       "1                     [Ok, lar, Joking, wif, u, oni]  \n",
       "2  [Free, entry, in, 2, a, wkly, comp, to, win, F...  \n",
       "3  [U, dun, say, so, early, hor, U, c, already, t...  \n",
       "4  [Nah, I, dont, think, he, goes, to, usf, he, l...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "#function to apply tokenization\n",
    "def tokenize(text):\n",
    "    tokens = re.split(\"\\W+\", text)# W+ means all capital, small alphabets and integers 0-9\n",
    "    return tokens\n",
    "\n",
    "df[\"body_text_tokenized\"] = df[\"body_text_clean\"].apply(lambda x: tokenize(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ae4145fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Message</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nonstop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[Go, until, jurong, point, crazy, Available, o...</td>\n",
       "      <td>[Go, jurong, point, crazy, Available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "      <td>[Free, entry, 2, wkly, comp, win, FA, Cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[U, dun, say, so, early, hor, U, c, already, t...</td>\n",
       "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[Nah, I, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[Nah, I, dont, think, goes, usf, lives, around...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target                                            Message  \\\n",
       "0       0  Go until jurong point, crazy.. Available only ...   \n",
       "1       0                      Ok lar... Joking wif u oni...   \n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3       0  U dun say so early hor... U c already then say...   \n",
       "4       0  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Go until jurong point crazy Available only in ...   \n",
       "1                            Ok lar Joking wif u oni   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3        U dun say so early hor U c already then say   \n",
       "4  Nah I dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [Go, until, jurong, point, crazy, Available, o...   \n",
       "1                     [Ok, lar, Joking, wif, u, oni]   \n",
       "2  [Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3  [U, dun, say, so, early, hor, U, c, already, t...   \n",
       "4  [Nah, I, dont, think, he, goes, to, usf, he, l...   \n",
       "\n",
       "                                   body_text_nonstop  \n",
       "0  [Go, jurong, point, crazy, Available, bugis, n...  \n",
       "1                     [Ok, lar, Joking, wif, u, oni]  \n",
       "2  [Free, entry, 2, wkly, comp, win, FA, Cup, fin...  \n",
       "3      [U, dun, say, early, hor, U, c, already, say]  \n",
       "4  [Nah, I, dont, think, goes, usf, lives, around...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "def remove_stopwords(token):\n",
    "    text = [word for word in token if word not in stopwords]# to remove all stopwords\n",
    "    return text\n",
    "\n",
    "df[\"body_text_nonstop\"] = df[\"body_text_tokenized\"].apply(lambda x: remove_stopwords(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0ae07d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Message</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nonstop</th>\n",
       "      <th>body_text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[Go, until, jurong, point, crazy, Available, o...</td>\n",
       "      <td>[Go, jurong, point, crazy, Available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "      <td>[Free, entry, 2, wkly, comp, win, FA, Cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[U, dun, say, so, early, hor, U, c, already, t...</td>\n",
       "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[Nah, I, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[Nah, I, dont, think, goes, usf, lives, around...</td>\n",
       "      <td>[nah, i, dont, think, goe, usf, live, around, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target                                            Message  \\\n",
       "0       0  Go until jurong point, crazy.. Available only ...   \n",
       "1       0                      Ok lar... Joking wif u oni...   \n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3       0  U dun say so early hor... U c already then say...   \n",
       "4       0  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Go until jurong point crazy Available only in ...   \n",
       "1                            Ok lar Joking wif u oni   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3        U dun say so early hor U c already then say   \n",
       "4  Nah I dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [Go, until, jurong, point, crazy, Available, o...   \n",
       "1                     [Ok, lar, Joking, wif, u, oni]   \n",
       "2  [Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3  [U, dun, say, so, early, hor, U, c, already, t...   \n",
       "4  [Nah, I, dont, think, he, goes, to, usf, he, l...   \n",
       "\n",
       "                                   body_text_nonstop  \\\n",
       "0  [Go, jurong, point, crazy, Available, bugis, n...   \n",
       "1                     [Ok, lar, Joking, wif, u, oni]   \n",
       "2  [Free, entry, 2, wkly, comp, win, FA, Cup, fin...   \n",
       "3      [U, dun, say, early, hor, U, c, already, say]   \n",
       "4  [Nah, I, dont, think, goes, usf, lives, around...   \n",
       "\n",
       "                                   body_text_stemmed  \n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...  \n",
       "1                       [ok, lar, joke, wif, u, oni]  \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...  \n",
       "3      [u, dun, say, earli, hor, u, c, alreadi, say]  \n",
       "4  [nah, i, dont, think, goe, usf, live, around, ...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def stemming(t_text):\n",
    "    text = [ps.stem(word) for word in t_text]\n",
    "    return text\n",
    "\n",
    "df[\"body_text_stemmed\"] = df[\"body_text_nonstop\"].apply(lambda x: stemming(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "34fe0db1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Message</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nonstop</th>\n",
       "      <th>body_text_stemmed</th>\n",
       "      <th>body_text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[Go, until, jurong, point, crazy, Available, o...</td>\n",
       "      <td>[Go, jurong, point, crazy, Available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "      <td>[Free, entry, 2, wkly, comp, win, FA, Cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[U, dun, say, so, early, hor, U, c, already, t...</td>\n",
       "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[Nah, I, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[Nah, I, dont, think, goes, usf, lives, around...</td>\n",
       "      <td>[nah, i, dont, think, goe, usf, live, around, ...</td>\n",
       "      <td>[nah, i, dont, think, goe, usf, live, around, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target                                            Message  \\\n",
       "0       0  Go until jurong point, crazy.. Available only ...   \n",
       "1       0                      Ok lar... Joking wif u oni...   \n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3       0  U dun say so early hor... U c already then say...   \n",
       "4       0  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Go until jurong point crazy Available only in ...   \n",
       "1                            Ok lar Joking wif u oni   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3        U dun say so early hor U c already then say   \n",
       "4  Nah I dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [Go, until, jurong, point, crazy, Available, o...   \n",
       "1                     [Ok, lar, Joking, wif, u, oni]   \n",
       "2  [Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3  [U, dun, say, so, early, hor, U, c, already, t...   \n",
       "4  [Nah, I, dont, think, he, goes, to, usf, he, l...   \n",
       "\n",
       "                                   body_text_nonstop  \\\n",
       "0  [Go, jurong, point, crazy, Available, bugis, n...   \n",
       "1                     [Ok, lar, Joking, wif, u, oni]   \n",
       "2  [Free, entry, 2, wkly, comp, win, FA, Cup, fin...   \n",
       "3      [U, dun, say, early, hor, U, c, already, say]   \n",
       "4  [Nah, I, dont, think, goes, usf, lives, around...   \n",
       "\n",
       "                                   body_text_stemmed  \\\n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
       "1                       [ok, lar, joke, wif, u, oni]   \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "4  [nah, i, dont, think, goe, usf, live, around, ...   \n",
       "\n",
       "                                body_text_lemmatized  \n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...  \n",
       "1                       [ok, lar, joke, wif, u, oni]  \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...  \n",
       "3      [u, dun, say, earli, hor, u, c, alreadi, say]  \n",
       "4  [nah, i, dont, think, goe, usf, live, around, ...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer(t_text):\n",
    "    text = [wn.lemmatize(word) for word in t_text]\n",
    "    return text\n",
    "\n",
    "df[\"body_text_lemmatized\"] = df[\"body_text_stemmed\"].apply(lambda x: lemmatizer(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a44774",
   "metadata": {},
   "source": [
    "# email spam dectection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e82bbc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sakshi Tripathi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Sakshi Tripathi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Sakshi Tripathi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Sakshi Tripathi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Sakshi Tripathi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Sakshi Tripathi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Confusion Matrix:\n",
      "[[0 1]\n",
      " [0 0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       1.0\n",
      "           1       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.00      0.00      0.00       1.0\n",
      "weighted avg       0.00      0.00      0.00       1.0\n",
      "\n",
      "Enter an email text: go to hell\n",
      "The entered email is classified as spam.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Sample dataset \n",
    "data = {\n",
    "    'text': ['Discounts on luxury watches!', 'Hello, how are you?', 'Win a free iPhone now!', 'Meeting tomorrow at 10 AM'],\n",
    "    'label': [1, 0, 1, 0]  # 1 for spam, 0 for not spam (ham)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to clean and preprocess text data\n",
    "def preprocess_text(text):\n",
    "    # text preprocessing (e.g., removing punctuation, converting to lowercase)\n",
    "    return text\n",
    "\n",
    "# Applying text preprocessing\n",
    "df['clean_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Spliting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['clean_text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating TfidfVectorizer for feature extraction\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fiting and transforming the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Creating and training the Naive Bayes classifier\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Transforming the test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# for predictions\n",
    "predictions = naive_bayes_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluation of the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "class_report = classification_report(y_test, predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Classification Report:\\n{class_report}')\n",
    "\n",
    "# Users input for prediction\n",
    "user_input = input(\"Enter an email text: \")\n",
    "user_input_cleaned = preprocess_text(user_input)\n",
    "user_input_tfidf = tfidf_vectorizer.transform([user_input_cleaned])\n",
    "\n",
    "# prediction for user input\n",
    "user_input_prediction = naive_bayes_classifier.predict(user_input_tfidf)\n",
    "\n",
    "if user_input_prediction[0] == 1:\n",
    "    print(\"The entered email is classified as spam.\")\n",
    "else:\n",
    "    print(\"The entered email is not spam (ham).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
